\documentclass[12pt]{article}
\pagestyle{empty}
\begin{document}

\title{Quantifying Rhythmic Synchrony}
\date{}

\maketitle

While the topics of automatic beat and onset detection have seen a good deal of recent research focus, relatively little work has been done on the computational analysis of rhythmic structure and synchronization.  The relative timing of notes played by individual performers in a piece of music can indicate the piece's genre and style as well as the performer's skill and intent.  We propose a novel technique for measuring the rhythmic synchronization of a piece of music and test its application in a variety of settings.  Our approach first calculates a perceptual strength function using a first order difference of successive Mel-scaled magnitude spectra.  The entropy of the cross-correlation of different perceptual strength functions is used to measure their rhythmic similarity.  To evaluate this technique, we first show that our measure correlates closely with certain human-annotated tags applied to a variety of music.  We also compare our metric with ``unity of ensemble sound'' and ``coherence'' scores assigned by expert judges to different performances of a piece of jazz music.  Finally, we show that using the relative entropy in each frequency band can improve beat detection algorithms.

\end{document}